<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-icon.png">
    <link rel="icon" type="image/png" href="/img/favicon.png">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <title>Generative AI as a Software Service</title>
    <meta content='width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0, shrink-to-fit=no' name='viewport' />
    
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700,200" rel="stylesheet" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css" />
    
    <link href="../css/bootstrap.min.css" rel="stylesheet" />
    <link href="../css/now-ui-kit.css?v=1.1.0" rel="stylesheet" />
    <link href="../css/demo.css" rel="stylesheet" />
    <link href="../css/sbst.css" rel="stylesheet" />
  <link rel="stylesheet" href="../css/highlight.min.css"><link rel="stylesheet" href="../css/sbst.css">
</head>

  
	<body class="landing-page sidebar-collapse">
    
    <nav class="navbar navbar-expand-lg bg-primary fixed-top navbar-transparent " color-on-scroll="400">
        <div class="container">
            <div class="navbar-translate">
                <a class="navbar-brand" href="../index.html"  rel="tooltip" title="" data-placement="bottom">
                    Generative AI as a Software Service
                </a>
                <button class="navbar-toggler navbar-toggler" type="button" data-toggle="collapse" data-target="#navigation" aria-controls="navigation-index" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-bar bar1"></span>
                    <span class="navbar-toggler-bar bar2"></span>
                    <span class="navbar-toggler-bar bar3"></span>
                </button>
            </div>
            <div class="collapse navbar-collapse justify-content-end" id="navigation" data-nav-image="/img/blurred-image-1.jpg">
              <ul class="navbar-nav  ml-auto">
      
                <li class="nav-item">
                  <a class="nav-link" href="../organisation/">
                    <img src="../img/people.png" height="19px" width="19px">
                    <span>Organization</span>
                  </a>
                </li>
       
                
              
                
                <li class="nav-item">
                  <a class="nav-link" href="../tools/">
                    <img src="../img/debug.png" height="16px" width="16px">
                    <span>Tool Competition</span>
                  </a>
                </li>
        
      
        
              <li class="nav-item">
                <a class="nav-link" href="../keynotes/">
                    <img src="../img/calendar.png" height="13px" width="13px">
                  <span>Keynote &amp; Tutorial</span>
                </a>
              </li>
              
            
              
              <li class="nav-item">
                <a class="nav-link" href="../program/">
                    <img src="../img/calendar.png" height="13px" width="13px">
                  <span>Program</span>
                </a>
              </li>

              <li class="nav-item">
                <a class="nav-link" href="../social-event/">
                    <img src="../img/location.png" height="15px" width="15px">
                  <span>Social event</span>
                </a>
              </li>
              
            
              
              <li class="nav-item">
                <a class="nav-link" href="../venue/">
                    <img src="../img/location.png" height="15px" width="15px">
                  <span>Venue</span>
                </a>
              </li>
              
      
                </ul>
            </div>
        </div>
    </nav>
    

    
    <div class="wrapper">
      
        <div class="page-header page-header-small" filter-color="blue">
            <div class="page-header-image" data-parallax="true" style="background-image: url('../img/Skyline.jpg');">
            </div>
            <br>


<div class="container">
  <div class="content-center">
                    <h1 class="title">ICSOC 2024</h1>
                    <div class="text-center">
                       <h5>The 3rd Intl. Workshop on Generative AI as a Software Service</h6>
                        <!-- <h5>Co-located with <a href="https://conf.researchr.org/home/icse-2023" style="color:white">ICSOC 2023</a></h5> -->
                            <h5>December 03-06 2024, Tunis, Tunisia</h5>
<!--<a href="" class="btn btn-primary btn-icon btn-round"><i class="fa fa-facebook-square"></i></a>-->
        <a href="https://twitter.com/NLBSE_workshop" class="btn btn-primary btn-icon btn-round"> <i class="fa fa-twitter"></i></a>

    </div>
  </div>
</div>

            
        </div>
        <div class="section">
            <div class="container">
              
            
<div class="row">
  <div class="col-md-8 ml-auto mr-auto text-left">
  
        <div class="section section-team text-center">
            <div class="container">
                <h2 class="title">Keynote Talk</h2>
                <div class="team">
                    <!--<div class="row">
                      <div class="col-sm">
                        <div class="team-player">
                          <img src="../img/davidlo.jpg" alt="Thumbnail Image" class="rounded-circle img-fluid img-raised">
                          <h4 class="title">David Lo</h4>
                          <p class="category text-primary">Singapore Management University, Singapore</p>
                            <a href="http://www.mysmu.edu/faculty/davidlo/" class="btn btn-primary btn-icon btn-round"><i class="fa fa-id-card-o"></i></a>
                            <p class="category text-primary">Automated Bug Management: Reflections and the Road Ahead</p>-->
                          <!--<p><a href="" target="_blank">» Slides</a></p>-->
                          <!--<p class="text-left">
                            <strong>Abstract</strong>:
                             For many projects, bug reports, predominantly written in natural language, are submitted daily to issue tracking systems. The number of such reports is often too many for busy software engineers to manually handle and eventually resolve in a timely fashion. Also, the resolution of each report often requires many steps, e.g., detecting invalid reports, assigning the reports to engineers with the right expertise, finding the buggy files requiring changes, fixing the buggy files, etc. Incorrect decisions made for any of these steps can slow down the resolution of the bug report. To help reduce engineers’ workload and improve the reliability of systems, in the last decade, many automated solutions have been proposed for various steps in the bug management and resolution process. This talk will first do a reflection on the hundreds of studies done in this popular area of Natural-Language Based Software Engineering (NLBSE), highlighting success cases and the explored directions. It will then highlight interesting future work in the road ahead, describing important unsolved problems and untapped opportunities.  
                          </p>
                          <p>  
                            <b>Automated Bug Management: Reflections & the Road Ahead</b> <a href="../img/Automated-Bug-Management_NLBSE24.pdf" target="_blank"> <img src="../img/pdf.png" style="width:20px;height:20px;"> </a>
                          </p>
                          

                          <p class="text-left">
                            <strong>Biography</strong>:
                             David Lo is a Professor of Computer Science at the School of Computing and Information Systems, Singapore Management University. He leads the SOftware Analytics Research (SOAR) group. His research interest is in the intersection of software engineering, cybersecurity, and data science, encompassing socio-technical aspects and analysis of different kinds of software artifacts, with the goal of improving software quality and security, and developer productivity. He has won more than 15 international research and service awards, including 2 Most Influential Paper (or Test-of-Time) Awards and 6 ACM SIGSOFT Distinguished Paper Awards. He has served in more than 30 organizing committees of conferences and is currently serving on the SIGSOFT Executive Committee, Editorial Boards of TSE, TRel, and EMSE, and as a PC Co-Chair of ESEC/FSE 2024 and ICSOC 2025. He is an IEEE Fellow, NRF Investigator, Fellow of Automated Software Engineering, and ACM Distinguished Member. 
                          </p>
                        </div>
                      </div>
                    </div>-->

                    <!--<div class="row">
                      <div class="col-sm">
                        <div class="team-player">
                          <img src="../img/ziegler.jpeg" alt="Thumbnail Image" class="rounded-circle img-fluid img-raised">
                          <h4 class="title">Albert Ziegler</h4>
                          <p class="category text-primary">Github, USA</p>
                            <a href="https://githubnext.com/team/wunderalbert/" class="btn btn-primary btn-icon btn-round"><i class="fa fa-id-card-o"></i></a>-->
                            <!--<p class="category text-primary">Trends and Opportunities in the Application of Large Language Models: The Quest for Maximum Effect</p>-->
                          <!--<p><a href="" target="_blank">» Slides</a></p>-->
                          <!--<p class="text-left">
                            <strong>Abstract</strong>: As large language models become more and more sophisticated, the machine learning problem "How to train a great new model so it best solves my task" increasingly pivots to "How to run a great existing model so it best solves my task".</p> 
                            <p class="text-left">This is easier said than done and requires reconciliation of four goals:</p>
			    <p class="text-left">
                            <ol class="text-left">
                              <li>How to communicate the problem and the format in which you expect your answer;</li>
                              <li>How to communicate all background information the model might need to arrive at that answer;</li>
                              <li>How to communicate with the model robustly, in particular in a way that it is used to from its training set;</li>
                              <li>How to keep the question short in order to adhere to the context window and save computing time and cost.</li>
                           </ol>
			   </p>
                           <p class="text-left">These goals are almost always conflicting. For example, an established strategy for 1 is few-shotting, but in particular for source code, this will often be very different in style to the model's training set, can easily bias the model, and uses lots of space that could otherwise be used for background information.</p>
                           <p class="text-left">I discuss strategies for addressing each of these goals in the code domain, as well as methods for balancing them against each other. I will in particular focus on the example of GitHub Copilot and related AI for software development projects.</p>

                          </p>-->
                          <!--<p class="text-left">
                            <strong>Title</strong>:
                            The First Derivative of Code — Applying Foundation Models to Code Changes<br><br>
                             <strong>Abstract</strong>:

                             LLMs are trained on documents, and LLMs for code are trained on documents describing code,
                             often the current state of files on main from selected projects on software engineering platforms like GitHub.<br><br>
                             
                             But software engineering is not about writing code, it’s about changing code.
                             An LLM that can only predict the second half of a finished code file
                             is subtly, but critically, off target for a software engineering task.<br><br>
                             
                             First, I’ll discuss how to address these problems within current parameters:
                             how can we make existing foundation models used to snapshots of source code deal effectively with code edits.
                             I’ll delve into prompting strategies and different “edit schemes”, i.e. ways to format edits in a model friendly way.<br><br>
                             
                             Then, I’ll address foundation models purely dedicated to code changes,
                             and models augmented with some change-understanding capability,
                             trying to draw conclusions about their eventual staying power
                             and the future of models that focus not on the current state, but on the evolution of code.<br>
                            </p>
                          <p class="text-left">
                            <strong>Biography</strong>:
                            Albert Ziegler is a principal machine learning engineer with a background in Mathematics and a home at GitHub Next, GitHub's innovation and future group. His main interests are combinations of deductive and intuitive reasoning to improve the software development experience. He's previously worked on developer productivity, ML guided CodeQL, and he was part of the trio that conceived and then implemented the GitHub Copilot project. His most recent projects include Copilot Radar and AI for Pull Requests.</p>
                        </div>
                      </div>
                    </div>-->

                    <div class="row">
                      <div class="col-sm">
                        <div class="team-player">
                          <img src="../img/Michael_Pradel.jpg" alt="Thumbnail Image" class="rounded-circle img-fluid img-raised">
                          <h4 class="title">Michael Pradel</h4>
                          <p class="category text-primary">University of Stuttgart, Germany</p>
                            <a href="https://software-lab.org/people/Michael_Pradel.html" class="btn btn-primary btn-icon btn-round"><i class="fa fa-id-card-o"></i></a>
                            <!--<p class="category text-primary">Trends and Opportunities in the Application of Large Language Models: The Quest for Maximum Effect</p>-->
                          <!--<p><a href="" target="_blank">» Slides</a></p>-->
                          <!--<p class="text-left">
                            <strong>Abstract</strong>: As large language models become more and more sophisticated, the machine learning problem "How to train a great new model so it best solves my task" increasingly pivots to "How to run a great existing model so it best solves my task".</p> 
                            <p class="text-left">This is easier said than done and requires reconciliation of four goals:</p>
			    <p class="text-left">
                            <ol class="text-left">
                              <li>How to communicate the problem and the format in which you expect your answer;</li>
                              <li>How to communicate all background information the model might need to arrive at that answer;</li>
                              <li>How to communicate with the model robustly, in particular in a way that it is used to from its training set;</li>
                              <li>How to keep the question short in order to adhere to the context window and save computing time and cost.</li>
                           </ol>
			   </p>
                           <p class="text-left">These goals are almost always conflicting. For example, an established strategy for 1 is few-shotting, but in particular for source code, this will often be very different in style to the model's training set, can easily bias the model, and uses lots of space that could otherwise be used for background information.</p>
                           <p class="text-left">I discuss strategies for addressing each of these goals in the code domain, as well as methods for balancing them against each other. I will in particular focus on the example of GitHub Copilot and related AI for software development projects.</p>

                          </p>-->
                          <!--<p class="text-left">
                             <strong>Abstract</strong>:
                             The First Derivative of Code — Applying Foundation Models to Code Changes<br><br>

                             LLMs are trained on documents, and LLMs for code are trained on documents describing code,
                             often the current state of files on main from selected projects on software engineering platforms like GitHub.<br><br>
                             
                             But software engineering is not about writing code, it’s about changing code.
                             An LLM that can only predict the second half of a finished code file
                             is subtly, but critically, off target for a software engineering task.<br><br>
                             
                             First, I’ll discuss how to address these problems within current parameters:
                             how can we make existing foundation models used to snapshots of source code deal effectively with code edits.
                             I’ll delve into prompting strategies and different “edit schemes”, i.e. ways to format edits in a model friendly way.<br><br>
                             
                             Then, I’ll address foundation models purely dedicated to code changes,
                             and models augmented with some change-understanding capability,
                             trying to draw conclusions about their eventual staying power
                             and the future of models that focus not on the current state, but on the evolution of code.<br>
                            </p>-->
                          <p class="text-left">
                            <strong>Title</strong>:
                            Neuro-Symbolic Developer Tools for Analyzing, Executing, and Repairing Code<br><br>
                            <strong>Abstract</strong>:
                            Developer productivity and software quality critically depend on effective software development tools. Traditional, symbolic program analysis tools are often limited in their ability to understand developer intention and rely on various hand-crafted heuristics. Neural software analysis addresses these limitations, but remains unaware of the formal semantics of a program and hence easily misses facts and rules that are actually well known. This talk argues that carefully combining neural and symbolic reasoning provides an effective means to address various challenging software development problems. To illustrate this point, I will describe our 8-year long journey of creating neuro-symbolic developer tools, ranging from learning-based bug detectors and type predictors, to our most recent work on learning-guided execution and program repair based on an autonomous LLM-based agent. I will discuss lessons learned on this journey and conclude with an outline of open challenges waiting to be addressed in order to close the gap between symbolic and neural software developer tools.
                            <br><br>
                            <strong>Biography</strong>:
                            Michael Pradel is a full professor at the University of Stuttgart, which he joined after a PhD at ETH Zurich, a post-doc at UC Berkeley, an assistant professorship at TU Darmstadt, and a sabbatical at Facebook. His research interests span software engineering, programming languages, security, and machine learning, with a focus on tools and techniques for building reliable, efficient, and secure software. In particular, he is interested in neural software analysis, analyzing web applications, dynamic analysis, and test generation. Michael has been recognized through the Ernst-Denert Software Engineering Award, an Emmy Noether grant by the German Research Foundation (DFG), an ERC Starting Grant, best/distinguished paper awards at FSE (3x), ISSTA, ASE, and ASPLOS, and by being named an ACM Distinguished Member.</p>
                        </div>
                      </div>
                    </div>

                </div>
		<br><br>
<!--                <h2 class="title">Tutorial</h2>-->
<!--		<div class="team">-->
<!--                    <div class="row">-->
<!--                      <div class="col-sm">-->
<!--                        <div class="team-player">-->
<!--                          <img src="/img/headshots/alessio2.jpg" alt="Thumbnail Image" class="rounded-circle img-fluid img-raised">-->
<!--                          <img src="/img/headshots/marc.jpg" alt="Thumbnail Image" class="rounded-circle img-fluid img-raised">-->
<!--                          <img src="/img/headshots/pascale.jpg" alt="Thumbnail Image" class="rounded-circle img-fluid img-raised">-->


<!--                          <h4 class="title">Alessio Gambi,<sup>1</sup> Marc Müller,<sup>2</sup> and Pascale Maul<sup>2</sup></h4>-->
<!--                          <p class="category text-primary">Université Polytechnique Hauts-de-France,<sup>1</sup> BeamNG.GmbH<sup>2</sup></p>-->
<!--                          <p class="category text-primary">Simulation-based Testing using <a href="http://beamng.tech/" target="_blank">BeamNG.tech</a></p>-->
<!--                          <p class="text-left">-->
<!--                            <strong>Abstract</strong>: In this tutorial, we cover the basics of simulation-based testing of Self-driving car software and exemplify how <a href="http://beamng.tech/" target="_blank">BeamNG.tech</a>, a state-of-art soft-body simulator, enables to generate driving scenarios suitable as test cases automatically. We conclude the tutorial with some examples of advanced features provided by the simulator that might help to create complex driving scenarios and help in training driving agents.-->
<!--                          </p>-->
<!--                          <p class="text-left">-->
<!--                            <strong>Biography</strong>: <br />-->
<!--                            <strong>Dr. Alessio Gambi</strong> is a postdoc at the University of Passau. He holds a Ph.D. in Informatics from the University of Lugano, two Ms.C. degrees in Computer Science and Computer Systems Engineering from the University of Illinois at Chicago and Politecnico of Milan.  Dr. Gambi's research interests span  Software Testing and Analysis,  Self-Driving Cars, Cloud computing, and Computer Science Education.-->
<!--                          </p>-->
<!--                          &lt;!&ndash;-->
<!--                          <a href="http://www.martinezmatias.com/" class="btn btn-primary btn-icon btn-round"><i class="fa fa-id-card-o"></i></a>-->
<!--                          <a href="https://github.com/martinezmatias" class="btn btn-primary btn-icon btn-round"><i class="fa fa-github"></i></a>-->
<!--                          <a href="https://twitter.com/Matias_MSM" class="btn btn-primary btn-icon btn-round"><i class="fa fa-twitter"></i></a>-->
<!--                          &ndash;&gt;-->

<!--                          <p class="text-left">-->
<!--                            <strong>Marc Müller</strong> is a Programmer and Research Specialist at BeamNG.GmbH. He holds an Ms.C. in Computer Science from the University of Saarland, Germany. His expertise is on Automated Generation using Genetic Algorithms and Procedural Content Generation. Marc's AsFault is one of the reference work in testing self-driving car software using procedural content generation and one of the main drivers behind the <a href="http://beamng.tech/" target="_blank">BeamNG.tech</a> initiative.-->
<!--                          </p>-->
<!--                          <p class="text-left">-->
<!--                            <strong>Pascale Maul</strong> is a Programmer and Research Specialist at BeamNG.GmbH. She holds an Ms.C. in Informatics from the University of Bremen, Germany. She's an expert on Deep Learning, a research enthusiast, and the most recent addition to the <a href="http://beamng.tech/" target="_blank">BeamNG.tech</a> team.-->
<!--                          </p>-->
<!--                        </div>-->
<!--                      </div>-->
<!--                    </div>-->
<!--                </div>-->
             </div>
       </div>

  </div>   
</div>


            </div>
        </div>
      <footer class="footer" data-background-color="black">
  <div class="container">
    <nav>
	    <ul>
	    
        <li>
          <a href="/"><i class='fa fa-balance-scale'></i> GAISS&#39;24</a>
        </li>
      
      </ul>
    </nav>
  </div>
</footer>
    </div>
  </body>

<script src="/js/core/jquery.3.2.1.min.js" type="text/javascript"></script>
<script src="/js/core/popper.min.js" type="text/javascript"></script>
<script src="/js/core/bootstrap.min.js" type="text/javascript"></script>

<script src="/js/plugins/bootstrap-switch.js"></script>

<script src="/js/plugins/nouislider.min.js" type="text/javascript"></script>

<script src="/js/plugins/bootstrap-datepicker.js" type="text/javascript"></script>

<script src="/js/now-ui-kit.js?v=1.1.0" type="text/javascript"></script>
<script type="text/javascript">
    $(document).ready(function() {
        
        nowuiKit.initSliders();
    });

    function scrollToDownload() {

        if ($('.section-download').length != 0) {
            $("html, body").animate({
                scrollTop: $('.section-download').offset().top
            }, 1000);
        }
    }
</script>

    
    
    
      
    
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>

      

      
      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    <script async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
    
    
</html>
